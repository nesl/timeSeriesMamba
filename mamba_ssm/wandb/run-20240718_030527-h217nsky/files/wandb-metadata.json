{
    "os": "Linux-5.4.0-150-generic-x86_64-with-glibc2.27",
    "python": "3.9.19",
    "heartbeatAt": "2024-07-18T10:05:27.617724",
    "startedAt": "2024-07-18T10:05:27.209136",
    "docker": null,
    "cuda": null,
    "args": [
        "--task_name",
        "long_term_forecast",
        "--is_training",
        "1",
        "--root_path",
        "./dataset/ETT-small/",
        "--data_path",
        "ETTh2.csv",
        "--model_id",
        "ETTh2_512_96",
        "--model",
        "BackboneModel",
        "--data",
        "ETTh2",
        "--features",
        "M",
        "--seq_len",
        "512",
        "--label_len",
        "48",
        "--pred_len",
        "96",
        "--factor",
        "3",
        "--enc_in",
        "7",
        "--dec_in",
        "7",
        "--c_out",
        "7",
        "--des",
        "Exp",
        "--itr",
        "1",
        "--d_model",
        "32",
        "--d_ff",
        "128",
        "--batch_size",
        "16",
        "--learning_rate",
        "0.01",
        "--llm_layers",
        "32",
        "--train_epochs",
        "30",
        "--model_comment",
        "checkpoints/ETTh2_l32_d32_e30_mMambaBackbone_n130m",
        "--save_checkpoints",
        "0",
        "--llm_model",
        "MambaBackbone",
        "--llm_dim",
        "768",
        "--num_params",
        "130m"
    ],
    "state": "running",
    "program": "/home/oliver/Desktop/mamba/mamba_ssm/train.py",
    "codePathLocal": "train.py",
    "codePath": "mamba_ssm/train.py",
    "git": {
        "remote": "git@github.com:nesl/timeSeriesMamba.git",
        "commit": "73e58673af00f13f37910d1f4e84a985f54b837c"
    },
    "email": "owang235@gmail.com",
    "root": "/home/oliver/Desktop/mamba",
    "host": "Nesl-Predator",
    "username": "oliver",
    "executable": "/home/oliver/anaconda3/envs/Mamba2/bin/python",
    "cpu_count": 16,
    "cpu_count_logical": 32,
    "cpu_freq": {
        "current": 2124.458562500001,
        "min": 2200.0,
        "max": 3400.0
    },
    "cpu_freq_per_core": [
        {
            "current": 2066.431,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 1888.425,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2062.197,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2325.071,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 1887.658,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 1992.425,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 1888.969,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2144.396,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 1914.996,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2075.311,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2183.506,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2190.609,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2181.556,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 1825.502,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 1873.624,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2590.197,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 1974.18,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 3082.462,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2192.87,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2255.404,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2186.677,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2070.108,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2006.232,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2180.885,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2188.372,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2145.416,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2186.266,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2144.965,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2188.819,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 1943.052,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 1942.605,
            "min": 2200.0,
            "max": 3400.0
        },
        {
            "current": 2203.488,
            "min": 2200.0,
            "max": 3400.0
        }
    ],
    "disk": {
        "/": {
            "total": 1832.2072448730469,
            "used": 1712.053653717041
        }
    },
    "gpu": "NVIDIA RTX A6000",
    "gpu_count": 2,
    "gpu_devices": [
        {
            "name": "NVIDIA RTX A6000",
            "memory_total": 51527024640
        },
        {
            "name": "NVIDIA RTX A6000",
            "memory_total": 51527024640
        }
    ],
    "memory": {
        "total": 125.72471618652344
    }
}
